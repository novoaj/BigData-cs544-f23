{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5b71b1-8b9d-4f94-90e8-f47dc6756e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os.path # https://www.freecodecamp.org/news/how-to-check-if-a-file-exists-in-python/\n",
    "import pyarrow as pa\n",
    "import pyarrow.fs\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9320374c-6d67-43d9-8f69-4a39b3af69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured Capacity: 25821052928 (24.05 GB)\n",
      "Present Capacity: 15687532783 (14.61 GB)\n",
      "DFS Remaining: 15429824512 (14.37 GB)\n",
      "DFS Used: 257708271 (245.77 MB)\n",
      "DFS Used%: 1.64%\n",
      "Replicated Blocks:\n",
      "\tUnder replicated blocks: 167\n",
      "\tBlocks with corrupt replicas: 0\n",
      "\tMissing blocks: 90\n",
      "\tMissing blocks (with replication factor 1): 90\n",
      "\tLow redundancy blocks with highest priority to recover: 167\n",
      "\tPending deletion blocks: 0\n",
      "Erasure Coded Block Groups: \n",
      "\tLow redundancy block groups: 0\n",
      "\tBlock groups with corrupt internal blocks: 0\n",
      "\tMissing block groups: 0\n",
      "\tLow redundancy blocks with highest priority to recover: 0\n",
      "\tPending deletion blocks: 0\n",
      "\n",
      "-------------------------------------------------\n",
      "Live datanodes (1):\n",
      "\n",
      "Name: 172.19.0.5:9866 (project-4-pandas4-dn-1.project-4-pandas4_default)\n",
      "Hostname: 7148d45c935e\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 25821052928 (24.05 GB)\n",
      "DFS Used: 257708271 (245.77 MB)\n",
      "Non DFS Used: 10116742929 (9.42 GB)\n",
      "DFS Remaining: 15429824512 (14.37 GB)\n",
      "DFS Used%: 1.00%\n",
      "DFS Remaining%: 59.76%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Sun Oct 29 21:31:14 GMT 2023\n",
      "Last Block Report: Sun Oct 29 21:27:38 GMT 2023\n",
      "Num of Blocks: 244\n",
      "\n",
      "\n",
      "Dead datanodes (1):\n",
      "\n",
      "Name: 172.19.0.4:9866 (172.19.0.4)\n",
      "Hostname: 0e3fe0795835\n",
      "Decommission Status : Normal\n",
      "Configured Capacity: 25821052928 (24.05 GB)\n",
      "DFS Used: 271276941 (258.71 MB)\n",
      "Non DFS Used: 10103059571 (9.41 GB)\n",
      "DFS Remaining: 15429939200 (14.37 GB)\n",
      "DFS Used%: 1.05%\n",
      "DFS Remaining%: 59.76%\n",
      "Configured Cache Capacity: 0 (0 B)\n",
      "Cache Used: 0 (0 B)\n",
      "Cache Remaining: 0 (0 B)\n",
      "Cache Used%: 100.00%\n",
      "Cache Remaining%: 0.00%\n",
      "Xceivers: 0\n",
      "Last contact: Sun Oct 29 21:29:11 GMT 2023\n",
      "Last Block Report: Sun Oct 29 21:27:38 GMT 2023\n",
      "Num of Blocks: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q8: how many live DataNodes are in the cluster?\n",
    "!hdfs dfsadmin -fs hdfs://boss:9000 -report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df68a45e-ef4e-40d2-ae5d-9b6b67224e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e54b605-1862-49dc-8665-9aa63fec1f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lost': 90, '7148d45c935e': 77}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9: how are the blocks of single.csv distributed across the DataNode containers?\n",
    "url = \"http://boss:9870/webhdfs/v1/single.csv?op=GETFILESTATUS\"\n",
    "r = requests.get(url)\n",
    "#r.raise_for_status()\n",
    "file_status = r.json()\n",
    "\n",
    "blockSize = file_status[\"FileStatus\"][\"blockSize\"]\n",
    "length = file_status[\"FileStatus\"][\"length\"]\n",
    "location_occurrences = {}\n",
    "valid_blocks = []\n",
    "\n",
    "idx = 0\n",
    "while idx < length:\n",
    "    url = f\"http://boss:9870/webhdfs/v1/single.csv?op=OPEN&offset={idx}&noredirect=true&length=100\"\n",
    "    r_1 = requests.get(url)\n",
    "    status_code = r_1.status_code\n",
    "    if status_code == 403:\n",
    "        if not \"lost\" in location_occurrences:\n",
    "           location_occurrences[\"lost\"] = 0\n",
    "        location_occurrences[\"lost\"] += 1\n",
    "    else:\n",
    "        # url = f\"http://boss:9870/webhdfs/v1/single.csv?op=OPEN&offset={idx}&noredirect=false&length=100\"\n",
    "        # r_2 = requests.get(url)\n",
    "        valid_blocks.append(r_1.json())\n",
    "        location = r_1.json()[\"Location\"][7:19]\n",
    "        if not location in location_occurrences:\n",
    "            location_occurrences[location] = 0\n",
    "        location_occurrences[location] += 1\n",
    "    idx += blockSize\n",
    "    \n",
    "location_occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a709e353-fa00-4ad4-946e-814d52973539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d142883e-fc0d-4caf-a5a7-47eb7cb7a59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204798"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10: how many times does the text \"Single Family\" appear in the remaining blocks of single.csv?\n",
    "count = 0\n",
    "hdfs = pa.fs.HadoopFileSystem(\"boss\", 9000)\n",
    "\n",
    "with hdfs.open_input_file(\"/single.csv\") as f:\n",
    "    for idx in range(len(valid_blocks)):\n",
    "        offset = int(valid_blocks[idx][\"Location\"][102:])\n",
    "        output = f.read_at(blockSize, offset) # output is bytes\n",
    "        reader = (output.decode(\"UTF-8\")) # byte to str\n",
    "        count += reader.count(\"Single Family\")\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06fe75-29e3-4a15-b5b0-f9e69407391a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
