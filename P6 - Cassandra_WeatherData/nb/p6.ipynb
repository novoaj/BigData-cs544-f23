{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad9b09c5-1c90-494f-b2e8-ee33e01897bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, min, max, date_format, to_date\n",
    "from subprocess import check_output\n",
    "from cassandra import ConsistencyLevel\n",
    "import grpc\n",
    "import station_pb2\n",
    "import station_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "600a1d31-715e-47bc-9c05-6b20a3f5ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  86.02 KiB  16      100.0%            e8371820-8545-4295-a6ee-246e887e4985  rack1\n",
      "UN  172.21.0.2  86.01 KiB  16      100.0%            b10f2eec-791a-4d47-9d37-84dec8be4cc0  rack1\n",
      "UN  172.21.0.3  86.01 KiB  16      100.0%            8ff7e1fd-e673-40d7-a20d-491a81840f9a  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5c560d2-fa14-41c0-afb7-3f55d489fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a76b26c-07f7-4952-a9e6-08fb57223eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f93abf109d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"drop keyspace if exists weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "853f9972-35ac-4561-8f80-ac4b40e6fe6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f93abf10f10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"create keyspace weather with replication={'class': 'SimpleStrategy', 'replication_factor': 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6e087d6-0fbf-449f-9695-54f4df50429f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f93c45b0cd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "create type weather.station_record (\n",
    "    tmin INT,\n",
    "    tmax INT\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12529cb4-b51f-4c9f-8e63-044522e89f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f93abf112d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"\"\"\n",
    "CREATE TABLE weather.stations (\n",
    "    id TEXT,\n",
    "    name TEXT STATIC,\n",
    "    date DATE,\n",
    "    record weather.station_record,\n",
    "    PRIMARY KEY ((id), date)\n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f54a7a18-4041-47c9-8a62-a4fa2c27cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE weather.stations (\\n    id text,\\n    date date,\\n    name text static,\\n    record station_record,\\n    PRIMARY KEY (id, date)\\n) WITH CLUSTERING ORDER BY (date ASC)\\n    AND additional_write_policy = '99p'\\n    AND bloom_filter_fp_chance = 0.01\\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\\n    AND cdc = false\\n    AND comment = ''\\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\\n    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\\n    AND memtable = 'default'\\n    AND crc_check_chance = 1.0\\n    AND default_time_to_live = 0\\n    AND extensions = {}\\n    AND gc_grace_seconds = 864000\\n    AND max_index_interval = 2048\\n    AND memtable_flush_period_in_ms = 0\\n    AND min_index_interval = 128\\n    AND read_repair = 'BLOCKING'\\n    AND speculative_retry = '99p';\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1: What is the Schema of stations?\n",
    "cass.execute(\"describe table weather.stations\").one().create_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43848797-db0e-4371-87f2-0375a5983825",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95fcb5bd-f9d0-440f-8c2f-9231460e1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.text(\"ghcnd-stations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "242bc686-0494-400f-8c46-64150efcf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn(\"ID\", expr(\"substring(value, 1, 11)\"))\n",
    "df = df2.withColumn(\"STATE\", expr(\"substring(value, 39, 2)\"))\n",
    "df2 = df.withColumn(\"NAME\", expr(\"substring(value, 42, 30)\"))\n",
    "#df2.limit(20).toPandas()\n",
    "df2.createOrReplaceTempView(\"stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbad438b-5f25-42e6-9cc9-94dda50b4167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "row_list = df2.rdd.filter(lambda row: row[\"STATE\"] == \"WI\").collect()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3025f9d-ea14-45eb-8fe9-7d40c6e185a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_wi = cass.prepare(\"\"\"\n",
    "INSERT INTO weather.stations (id, name)\n",
    "VALUES (?, ?)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3e2ecb6-c3ef-4a29-bfe2-1b506faf8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n"
     ]
    }
   ],
   "source": [
    "print(len(row_list))\n",
    "for row in row_list:\n",
    "    # do cassandra with row[\"ID\"] and row[\"NAME\"]\n",
    "    # need to reuse query many times\n",
    "    cass.execute(insert_wi, (row[\"ID\"], row[\"NAME\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7658d205-5595-4ac5-acfd-42c85b6f5da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Aggregation query used without partition key\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(count=1313)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"SELECT COUNT(*) FROM weather.stations\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fd3ab5e-efb3-4c2a-be67-6d9929eba528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MADISON DANE CO RGNL AP'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2: what is the name corresponding to station ID USW00014837?\n",
    "cass.execute(\"select NAME from weather.stations where ID = 'USW00014837'\").one()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83d42411-da95-4d5d-86a2-3fecc305a8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9014250178872933741"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3: what is the token for the USC00470273 station?\n",
    "cass.execute(\"select token(ID) from weather.stations where ID = 'USC00470273'\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffe2c866-5bec-4a50-b513-c44649709d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example code for server.py insert\n",
    "# station = \"testID\"\n",
    "# date = \"2023-11-22\"\n",
    "# tmin = 1\n",
    "# tmax = 10\n",
    "# tmax2 = 11\n",
    "# insert_statement = cass.prepare(\"\"\"\n",
    "#             INSERT INTO weather.stations (id, date, record)\n",
    "#             VALUES (?, ?, { tmin: ?, tmax: ? })\n",
    "#             \"\"\")\n",
    "# insert_statement.consistency_level = ConsistencyLevel.ONE\n",
    "# cass.execute(insert_statement, (station, date, tmin, tmax))\n",
    "# cass.execute(insert_statement, (station, date, tmin, tmax2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ec676c6-751f-4703-94f5-527545800f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing max_statement for server.py after an insert with tmax != None\n",
    "# max_statement = cass.prepare(\"\"\"\n",
    "#             SELECT MAX(record.tmax) FROM weather.stations WHERE id = ?\n",
    "#         \"\"\")\n",
    "# record_id = 'testID'\n",
    "# max_statement.consistency_level = ConsistencyLevel.ONE\n",
    "# res = cass.execute(max_statement, (record_id,)).one()[0]\n",
    "# print(res, type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b59e186e-717f-4e40-a20d-b78608cd5983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nodetool ring\n",
    "list_output = check_output(\"nodetool ring\", shell=True).decode(\"utf-8\").split(\"\\n\")[4:-6]\n",
    "# list_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b80bde7-2ae0-45da-85ea-899f5f5c22fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-8853427648287254574,\n",
       " -8580441399010981377,\n",
       " -8254963957330515747,\n",
       " -7875282195771140498,\n",
       " -7484399498776043088,\n",
       " -7220663310655111380,\n",
       " -6794376809373981990,\n",
       " -6393102388083830828,\n",
       " -6096647894947553369,\n",
       " -5548725740592669071,\n",
       " -5444174982799304106,\n",
       " -5000605994712615080,\n",
       " -4386798465870345889,\n",
       " -4108457510690085831,\n",
       " -3909308884020402820,\n",
       " -3064932236529241064,\n",
       " -3036956894350053019,\n",
       " -2265103565868110780,\n",
       " -2019105489607626003,\n",
       " -1624664006626657824,\n",
       " -1201433556995275209,\n",
       " -1006682974724457746,\n",
       " -553163390286625012,\n",
       " -125677675769695670,\n",
       " 57658015048605649,\n",
       " 464688014455802003,\n",
       " 610238016941197970,\n",
       " 1282359947068152797,\n",
       " 1689610824388799628,\n",
       " 1877662316028552047,\n",
       " 2358115828293732336,\n",
       " 2933130830069391600,\n",
       " 3094031521004625977,\n",
       " 3754726645541538076,\n",
       " 3900495073147927099,\n",
       " 4173404328452227635,\n",
       " 4923681568720552455,\n",
       " 5416924334132819607,\n",
       " 5490499625661825737,\n",
       " 5972805369049743543,\n",
       " 6384288577211355106,\n",
       " 6908718541841258963,\n",
       " 7109522921358869034,\n",
       " 7324356201412898843,\n",
       " 7974293129725253744,\n",
       " 8087668373874983110,\n",
       " 8536036548084879988,\n",
       " 8933359400433592779]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = []\n",
    "for s in list_output:\n",
    "    numbers.append(int(s.split()[-1]))\n",
    "numbers = numbers[1:]\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32fa3495-f7de-4ec3-bf84-bed0fcd4c499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8853427648287254574"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4: what is the first vnode token in the ring following the token for USC00470273?\n",
    "# find token for this station\n",
    "# find the first bigger token compare with this token vnode \n",
    "token = cass.execute(\"select token(ID) from weather.stations where ID = 'USC00470273'\").one()[0]\n",
    "# first large num we ecnounter is the vnode this token belongs to\n",
    "# need to think about the wrap around case\n",
    "answer = None\n",
    "for idx in range(len(numbers)): # find the vnode that this token belongs to and return the next vnode\n",
    "    cur = numbers[idx]\n",
    "    # this is the answer or it isnt\n",
    "    # we have an answer if cur is greater than token\n",
    "    if cur > token:\n",
    "        answer = cur\n",
    "        break\n",
    "if not answer: answer = numbers[0]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f6808ed-5a61-4bb7-b07a-e2ff8a409547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip records.zip # only want to run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a4e1c5c-eeef-48d7-860e-4c3338f667cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"part-00000-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet\",\n",
    "\"part-00001-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet\",\n",
    "\"part-00002-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet\",\n",
    "\"part-00003-574ab704-2431-4c8b-9d88-6c635a467b99-c000.snappy.parquet\"]\n",
    "# could maybe avoid hardcoding by importing os/sys or something to read these parquets\n",
    "# (grab all files in this directory ending in \".snappy.parquet\")\n",
    "# https://spark.apache.org/docs/2.4.4/sql-data-sources-parquet.html\n",
    "Parquet0 = spark.read.parquet(\"records.parquet/\" + filenames[0])\n",
    "Parquet1 = spark.read.parquet(\"records.parquet/\" + filenames[1])\n",
    "Parquet2 = spark.read.parquet(\"records.parquet/\" + filenames[2])\n",
    "Parquet3 = spark.read.parquet(\"records.parquet/\" + filenames[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a0eb01d-ae17-4baf-b32e-c951d2d52a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parquet0.createOrReplaceTempView(\"parquet0\")\n",
    "Parquet1.createOrReplaceTempView(\"parquet1\")\n",
    "Parquet2.createOrReplaceTempView(\"parquet2\")\n",
    "Parquet3.createOrReplaceTempView(\"parquet3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d51c9b5b-7cc1-4e42-87a4-d214ea95c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-----+--------------+\n",
      "|    station|    date|  tmin| tmax|formatted_date|\n",
      "+-----------+--------+------+-----+--------------+\n",
      "|USW00014837|20220222| -88.0|-38.0|    2022-02-22|\n",
      "|USW00014837|20220624| 200.0|322.0|    2022-06-24|\n",
      "|USW00014837|20220731| 161.0|278.0|    2022-07-31|\n",
      "|USW00014837|20220802| 150.0|306.0|    2022-08-02|\n",
      "|USW00014837|20220906| 117.0|256.0|    2022-09-06|\n",
      "|USW00014837|20220912| 117.0|161.0|    2022-09-12|\n",
      "|USW00014837|20221115| -10.0| 11.0|    2022-11-15|\n",
      "|USW00014837|20220408|   0.0| 22.0|    2022-04-08|\n",
      "|USW00014837|20221015|  -5.0|122.0|    2022-10-15|\n",
      "|USW00014837|20221216| -50.0|-22.0|    2022-12-16|\n",
      "|USW00014837|20220205|-188.0|-60.0|    2022-02-05|\n",
      "|USW00014837|20220420|  50.0|100.0|    2022-04-20|\n",
      "|USW00014837|20220508|  72.0|161.0|    2022-05-08|\n",
      "|USW00014837|20221116| -21.0| 11.0|    2022-11-16|\n",
      "|USW00014837|20220206| -77.0| 28.0|    2022-02-06|\n",
      "|USW00014837|20220810| 144.0|283.0|    2022-08-10|\n",
      "|USW00014837|20221203| -78.0| 50.0|    2022-12-03|\n",
      "|USW00014837|20220501|  83.0|122.0|    2022-05-01|\n",
      "|USW00014837|20221120|-121.0|  0.0|    2022-11-20|\n",
      "|USW00014837|20221121| -60.0| 50.0|    2022-11-21|\n",
      "+-----------+--------+------+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DFs have same schema, element can be tmin or tmax, value corresponds to this element\n",
    "# reformat date: https://spark.apache.org/docs/2.3.0/api/sql/index.html#date_format\n",
    "# https://stackoverflow.com/questions/49615307/changing-the-date-format-of-the-column-values-in-a-spark-dataframe\n",
    "# take min of TMIN and MAX of tmax for each station+date\n",
    "# https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-case.html\n",
    "# CASE WHEN kind of like if else, helps us process values if they are element=tmin/tmax\n",
    "# https://stackoverflow.com/questions/25157451/spark-sql-case-when-then\n",
    "# combine dfs and groupby station+date\n",
    "# https://stackoverflow.com/questions/905379/what-is-the-difference-between-join-and-union\n",
    "# UNION instead of join sort of stacks all the rows into one big df\n",
    "big_df = spark.sql(\"\"\"\n",
    "    SELECT station,\n",
    "    date,\n",
    "    MIN(CASE WHEN element = 'TMIN' THEN value END) as tmin,\n",
    "    MAX(CASE WHEN element = 'TMAX' THEN value END) as tmax\n",
    "    FROM (\n",
    "        SELECT * FROM parquet0\n",
    "        UNION ALL\n",
    "        SELECT * FROM parquet1\n",
    "        UNION ALL\n",
    "        SELECT * FROM parquet2\n",
    "        UNION ALL\n",
    "        SELECT * FROM parquet3\n",
    "    )\n",
    "    GROUP BY station,date\n",
    "\"\"\")\n",
    "big_df = big_df.withColumn(\"formatted_date\", date_format(to_date(col(\"date\"), \"yyyyMMdd\"), \"yyyy-MM-dd\"))\n",
    "big_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72e318ff-e2d3-4919-a8e2-7f40d6f940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take big_df, loop over rows and insert into server.py\n",
    "# making rpc calls to server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "483a5945-c166-4491-96e2-c54ed9c042b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel(\"127.0.0.1:5440\") \n",
    "stub = station_pb2_grpc.StationStub(channel)\n",
    "# stub.RecordTemps, stub.StationMax\n",
    "# iterate through big_df and feed in station=station, date=formatted_date, tmin=tmin, tmax=tmax\n",
    "# might have to format date from string into something CQL friendly for inserts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2ad339d-fa51-4c02-87e8-015d2eca01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sparkbyexamples.com/spark/spark-foreach-usage-with-examples/\n",
    "def send_row(row):\n",
    "    station = row[\"station\"]\n",
    "    date = row[\"formatted_date\"]\n",
    "    tmin = int(row[\"tmin\"])\n",
    "    tmax = int(row[\"tmax\"])\n",
    "    # print(type(station), type(date), type(tmin), type(tmax))\n",
    "    # print(station, date, tmin, tmax)\n",
    "    # if (station == 'USW00014837'):\n",
    "    #     print(type(station), type(date), type(tmin), type(tmax))\n",
    "    #     print(station, date, tmin, tmax)\n",
    "    res = stub.RecordTemps(station_pb2.RecordTempsRequest(\n",
    "        station = station,\n",
    "        date = date,\n",
    "        tmin = (tmin),\n",
    "        tmax = (tmax)\n",
    "        ))\n",
    "        \n",
    "# big_df.foreach(send_row) # send each row to server.py\n",
    "# issue with partitions, some partitions/cores have no idea what channel and stub are(?)\n",
    "for row in big_df.collect():\n",
    "    send_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b56891b-a663-4ab3-b5a4-ba6cfd4f0526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5: what is the max temperature ever seen for station USW00014837?\n",
    "r = stub.StationMax(station_pb2.StationMaxRequest(station = 'USW00014837'))\n",
    "r.tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90df1fcf-6396-4596-bf6d-9e2d50a21337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cass.execute(\"SELECT * FROM weather.stations WHERE id = 'USW00014837'\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e41b233-b149-41a2-88b6-c8c51c7e5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".option(\"spark.cassandra.connection.host\", \"p6-db-1,p6-db-2,p6-db-3\")\\\n",
    ".option(\"keyspace\", \"weather\")\\\n",
    ".option(\"table\", \"stations\")\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "70b5d61a-dbd6-4644-b261-8dd6fd1ecb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='parquet0', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='parquet1', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='parquet2', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='parquet3', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='stations', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6: what tables/views are available in the Spark catalog?\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9352b1f-02a3-4c13-8327-a90a9682b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'USW00014898': 102.93698630136986,\n",
       " 'USR0000WDDG': 102.06849315068493,\n",
       " 'USW00014837': 105.62739726027397,\n",
       " 'USW00014839': 89.6986301369863}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/23 04:55:15 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (java.nio.channels.NotYetConnectedException))\n"
     ]
    }
   ],
   "source": [
    "#q7: what is the average difference between tmax and tmin, for each of the four stations that have temperature records?\n",
    "rows_with_record = df.filter(col(\"record.tmin\").isNotNull() & col(\"record.tmax\").isNotNull()).collect()\n",
    "dict_differences = {} # id: total(tmax-tmin)\n",
    "dict_occurences = {} # id : occurences\n",
    "\n",
    "for row in rows_with_record:\n",
    "    if row[\"id\"] not in dict_differences:\n",
    "        # add to both dicts\n",
    "        dict_differences[row[\"id\"]] = row[\"record\"][\"tmax\"] - row[\"record\"][\"tmin\"]\n",
    "        dict_occurences[row[\"id\"]] = 1\n",
    "    else:\n",
    "        # update both dicts\n",
    "        dict_differences[row[\"id\"]] += row[\"record\"][\"tmax\"] - row[\"record\"][\"tmin\"]\n",
    "        dict_occurences[row[\"id\"]] += 1\n",
    "        \n",
    "\n",
    "results = {} # id : avg\n",
    "# loop to populate results\n",
    "for key in dict_differences:\n",
    "    results[key] = dict_differences[key] / dict_occurences[key]\n",
    "results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb45709b-88ef-4993-b9c0-a22bee304e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  182.34 KiB  16      100.0%            e8371820-8545-4295-a6ee-246e887e4985  rack1\n",
      "UN  172.21.0.2  188.24 KiB  16      100.0%            b10f2eec-791a-4d47-9d37-84dec8be4cc0  rack1\n",
      "DN  172.21.0.3  182.15 KiB  16      100.0%            8ff7e1fd-e673-40d7-a20d-491a81840f9a  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#q8: what does nodetool status output?\n",
    "!nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f4e43951-eef9-4f97-b3bb-bc0e0bcb24a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Need 3 replicas, but only have 2'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q9: if you make a StationMax RPC call, what does the error field contain in StationMaxReply reply?\n",
    "r = stub.StationMax(station_pb2.StationMaxRequest(station = 'USW00014837'))\n",
    "r.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d697749-abea-47af-95d4-8f362275bf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/23 04:57:38 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 111.36 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 140.8 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 04:58:40 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 220.16 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 04:59:43 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 286.72 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:00:44 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:01:45 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:02:38 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 435.2 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:03:41 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:04:44 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 583.68 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:05:47 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:06:43 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:07:42 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:08:46 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:09:41 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:10:37 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:11:31 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:12:32 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:13:35 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:14:33 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 594.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:15:28 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:16:31 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:17:30 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:18:33 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:19:36 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:20:39 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:21:42 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:22:45 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:23:48 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:24:51 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:25:51 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:26:45 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:27:41 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:28:44 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:29:40 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:30:43 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 582.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:31:46 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:32:38 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:33:31 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:34:30 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:35:33 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:36:36 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:37:31 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:38:32 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:39:33 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:40:36 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:41:39 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:42:42 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:43:38 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:44:39 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:45:40 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:46:40 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:47:41 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:48:43 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:49:43 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "23/11/23 05:50:46 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:51:50 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:52:53 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/23 05:53:55 WARN ChannelPool: [s0|p6-db-2/172.21.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=add2d1c1-e96f-40b0-b5c7-f030dacb594f, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700714921475}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 588.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 588.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 528.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 588.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 552.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 582.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 540.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 540.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 570.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 546.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 546.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.21.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.21.0.3', 9042)]. Last error: No route to host\n"
     ]
    }
   ],
   "source": [
    "#q10: if you make a RecordTempsRequest RPC call, what does error contain in the RecordTempsReply reply?\n",
    "res = stub.RecordTemps(station_pb2.RecordTempsRequest(\n",
    "        station = \"abcd\",\n",
    "        date = \"2023-11-22\",\n",
    "        tmin = -10,\n",
    "        tmax = 10\n",
    "        ))\n",
    "res.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb40696-12f1-4326-9f0b-e64e0d054c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
